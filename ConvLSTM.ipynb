{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl70BdgDaMXW9pfH04+Z6u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaFuego20/exchange-rate-forecasting/blob/main/ConvLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChOQDzOWE985"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8de413bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277c8991-818b-4cff-a5d1-6177c9174730"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import ConvLSTM2D, Flatten, Dense\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Set random seed for reproducibility ---\n",
        "os.environ['PYTHONHASHSEED'] = '2'\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "random.seed(2)\n",
        "np.random.seed(2)\n",
        "tf.random.set_seed(2)\n",
        "\n",
        "# --- Data Loading ---\n",
        "file_path_normalized = 'normalized_data.csv'\n",
        "file_path_original = 'merged_exchange_rates.csv'\n",
        "\n",
        "if not os.path.exists(file_path_normalized):\n",
        "    print(f\"Error: File not found at {file_path_normalized}\")\n",
        "    # Consider adding code here to handle missing files, e.g., download from a URL or prompt the user to upload\n",
        "    raise FileNotFoundError(f\"Required data file not found: {file_path_normalized}\")\n",
        "\n",
        "if not os.path.exists(file_path_original):\n",
        "    print(f\"Error: File not found at {file_path_original}\")\n",
        "    # Consider adding code here to handle missing files\n",
        "    raise FileNotFoundError(f\"Required data file not found: {file_path_original}\")\n",
        "\n",
        "\n",
        "try:\n",
        "    normalized_df = pd.read_csv(file_path_normalized)\n",
        "    original_df = pd.read_csv(file_path_original)\n",
        "    print(\"Data loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the data: {e}\")\n",
        "    raise\n",
        "\n",
        "\n",
        "# --- Data Preprocessing ---\n",
        "if 'Unnamed: 4' in original_df.columns:\n",
        "    original_df = original_df.drop('Unnamed: 4', axis=1)\n",
        "\n",
        "normalized_df['Date'] = pd.to_datetime(normalized_df['Date'], format='%d/%m/%Y')\n",
        "original_df['Date'] = pd.to_datetime(original_df['Date'], format='%d/%m/%Y')\n",
        "\n",
        "features = ['USD_NGN_Norm', 'EUR_NGN_Norm', 'GBP_NGN_Norm']\n",
        "original_currency_cols = ['USD_NGN', 'EUR_NGN', 'GBP_NGN']\n",
        "normalized_currency_cols = ['USD_NGN_Norm', 'EUR_NGN_Norm', 'GBP_NGN_Norm']\n",
        "\n",
        "# Define sequence length\n",
        "sequence_length = 30\n",
        "\n",
        "# Define a function to create sequences\n",
        "def create_sequences(data, sequence_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        X.append(data[i:(i + sequence_length)])\n",
        "        y.append(data[i + sequence_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Function to denormalize predictions and true values and calculate metrics\n",
        "def evaluate_denormalized(y_true_normalized, y_pred_normalized, original_df, currency_name):\n",
        "    original_min = original_df[currency_name].min()\n",
        "    original_max = original_df[currency_name].max()\n",
        "    y_true_denormalized = y_true_normalized * (original_max - original_min) + original_min\n",
        "    y_pred_denormalized = y_pred_normalized * (original_max - original_min) + original_min\n",
        "    rmse_denormalized = np.sqrt(mean_squared_error(y_true_denormalized, y_pred_denormalized))\n",
        "    mae_denormalized = mean_absolute_error(y_true_denormalized, y_pred_denormalized)\n",
        "    return rmse_denormalized, mae_denormalized\n",
        "\n",
        "# --- Define ConvLSTM Model Architecture ---\n",
        "def build_convlstm_model(input_shape, output_units):\n",
        "    model = Sequential()\n",
        "    model.add(ConvLSTM2D(filters=64, kernel_size=(1, 3), activation='relu', input_shape=input_shape, return_sequences=False))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=output_units, activation='linear'))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# --- Define Periods ---\n",
        "subsidy_removal_date = pd.to_datetime('2023-05-29')\n",
        "\n",
        "full_df = normalized_df.copy()\n",
        "pre_subsidy_df = normalized_df[normalized_df['Date'] < subsidy_removal_date].copy()\n",
        "post_subsidy_df = normalized_df[normalized_df['Date'] >= subsidy_removal_date].copy()\n",
        "\n",
        "periods = {\n",
        "    'Full': full_df,\n",
        "    'Pre-subsidy': pre_subsidy_df,\n",
        "    'Post-subsidy': post_subsidy_df\n",
        "}\n",
        "\n",
        "\n",
        "# --- Calculate Performance Metrics ---\n",
        "\n",
        "# Create a dictionary to store RMSE and MAE values\n",
        "performance_metrics = {currency: {'RMSE': {}, 'MAE': {}} for currency in original_currency_cols}\n",
        "\n",
        "# Iterate through each period and currency to calculate metrics\n",
        "print(\"--- Calculating Performance Metrics ---\")\n",
        "for period_name, period_df in periods.items():\n",
        "    print(f\"\\nProcessing {period_name} Period for Metrics...\")\n",
        "\n",
        "    if period_df.empty or len(period_df) <= sequence_length:\n",
        "        print(f\"Not enough data in {period_name} period to calculate metrics.\")\n",
        "        continue\n",
        "\n",
        "    data_for_sequences_period = period_df[features].values\n",
        "    X_period, y_period = create_sequences(data_for_sequences_period, sequence_length)\n",
        "\n",
        "    if len(X_period) == 0:\n",
        "         print(f\"Not enough data in {period_name} period to create sequences for metric calculation.\")\n",
        "         continue\n",
        "\n",
        "    X_period = X_period.reshape((X_period.shape[0], sequence_length, 1, X_period.shape[2], 1))\n",
        "\n",
        "    train_size_period = int(len(X_period) * 0.8)\n",
        "    if train_size_period == 0 or train_size_period == len(X_period):\n",
        "        print(f\"Not enough data in {period_name} period for an 80/20 train/test split for metric calculation.\")\n",
        "        continue\n",
        "\n",
        "    X_train_period, X_test_period = X_period[:train_size_period], X_period[train_size_period:]\n",
        "    y_train_period, y_test_period = y_period[:train_size_period], y_period[train_size_period:]\n",
        "\n",
        "    # Rebuild and train the model for this period to get the predictions\n",
        "    print(f\"Training model for {period_name} to calculate metrics...\")\n",
        "    model_period = build_convlstm_model(input_shape=(X_train_period.shape[1], X_train_period.shape[2], X_train_period.shape[3], X_train_period.shape[4]),\n",
        "                                        output_units=y_train_period.shape[1])\n",
        "    if X_train_period.shape[0] > 1 and X_train_period.shape[0] * 0.2 >= 1:\n",
        "        model_period.fit(X_train_period, y_train_period, epochs=50, batch_size=32, verbose=0, validation_split=0.2)\n",
        "    else:\n",
        "        model_period.fit(X_train_period, y_train_period, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "\n",
        "    if len(X_test_period) > 0:\n",
        "         y_pred_period = model_period.predict(X_test_period, verbose=0)\n",
        "    else:\n",
        "        print(f\"No test data available for {period_name} to calculate metrics.\")\n",
        "        continue\n",
        "\n",
        "    # Calculate and store metrics for each currency\n",
        "    if 'y_pred_period' in locals(): # Check if predictions were made for this period\n",
        "        print(f\"  Performance Metrics for {period_name} Test Set:\")\n",
        "        for i, currency_norm in enumerate(normalized_currency_cols):\n",
        "            currency_orig = original_currency_cols[i]\n",
        "            y_test_currency_norm = y_test_period[:, i]\n",
        "            y_pred_currency_norm = y_pred_period[:, i]\n",
        "\n",
        "            rmse_denorm, mae_denorm = evaluate_denormalized(\n",
        "                y_test_currency_norm,\n",
        "                y_pred_currency_norm,\n",
        "                original_df, # Use the full original_df for min/max scaling\n",
        "                currency_orig\n",
        "            )\n",
        "            performance_metrics[currency_orig]['RMSE'][period_name] = rmse_denorm\n",
        "            performance_metrics[currency_orig]['MAE'][period_name] = mae_denorm\n",
        "            print(f'    {currency_orig}: RMSE={rmse_denorm:.4f}, MAE={mae_denorm:.4f}')\n",
        "    else:\n",
        "        print(f\"Predictions were not generated for {period_name}. Skipping metric calculation.\")\n",
        "\n",
        "print(\"\\n--- Performance Metrics Calculation Complete ---\")\n",
        "\n",
        "\n",
        "# --- Generate and Save Plots as PDFs ---\n",
        "print(\"\\n--- Generating and Saving Plots as PDFs ---\")\n",
        "\n",
        "# Actual vs Predicted plots for each period and currency (as requested)\n",
        "for period_name, period_df in periods.items():\n",
        "    print(f\"\\nGenerating plots for {period_name} Period...\")\n",
        "    if period_df.empty or len(period_df) <= sequence_length:\n",
        "        print(f\"Skipping plots for {period_name} period due to insufficient data.\")\n",
        "        continue\n",
        "\n",
        "    data_for_sequences_period = period_df[features].values\n",
        "    X_period, y_period = create_sequences(data_for_sequences_period, sequence_length)\n",
        "\n",
        "    if len(X_period) == 0:\n",
        "         print(f\"Skipping plots for {period_name} period due to insufficient sequences.\")\n",
        "         continue\n",
        "\n",
        "    X_period = X_period.reshape((X_period.shape[0], sequence_length, 1, X_period.shape[2], 1))\n",
        "\n",
        "    train_size_period = int(len(X_period) * 0.8)\n",
        "    if train_size_period == 0 or train_size_period == len(X_period):\n",
        "        print(f\"Skipping plots for {period_name} period due to insufficient test data after split.\")\n",
        "        continue\n",
        "\n",
        "    X_train_period, X_test_period = X_period[:train_size_period], X_period[train_size_period:]\n",
        "    y_train_period, y_test_period = y_period[:train_size_period], y_period[train_size_period:]\n",
        "\n",
        "    # Rebuild and train the model for this period to get the predictions\n",
        "    model_period = build_convlstm_model(input_shape=(X_train_period.shape[1], X_train_period.shape[2], X_train_period.shape[3], X_train_period.shape[4]),\n",
        "                                        output_units=y_train_period.shape[1])\n",
        "    if X_train_period.shape[0] > 1 and X_train_period.shape[0] * 0.2 >= 1:\n",
        "        model_period.fit(X_train_period, y_train_period, epochs=50, batch_size=32, verbose=0, validation_split=0.2)\n",
        "    else:\n",
        "        model_period.fit(X_train_period, y_train_period, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "    if len(X_test_period) > 0:\n",
        "        y_pred_period = model_period.predict(X_test_period, verbose=0)\n",
        "\n",
        "        # Get the corresponding dates for the test set\n",
        "        test_dates_period = period_df['Date'].iloc[train_size_period + sequence_length:].reset_index(drop=True)\n",
        "\n",
        "        # Create a figure with subplots for each currency in this period\n",
        "        fig, axes = plt.subplots(nrows=len(original_currency_cols), ncols=1, figsize=(12, 18))\n",
        "        fig.suptitle(f'{period_name} Period: Actual vs Predicted for All Currencies', y=1.02) # Add a super title\n",
        "\n",
        "        for i, currency_orig in enumerate(original_currency_cols):\n",
        "            currency_norm = normalized_currency_cols[i]\n",
        "            y_test_currency_norm = y_test_period[:, i]\n",
        "            y_pred_currency_norm = y_pred_period[:, i]\n",
        "\n",
        "            # Denormalize the actual and predicted values for plotting\n",
        "            original_min = original_df[currency_orig].min()\n",
        "            original_max = original_df[currency_orig].max()\n",
        "            y_true_denormalized = y_test_currency_norm * (original_max - original_min) + original_min\n",
        "            y_pred_denormalized = y_pred_currency_norm * (original_max - original_min) + original_min\n",
        "\n",
        "            # Plot on the corresponding subplot\n",
        "            axes[i].plot(test_dates_period, y_true_denormalized, label='Actual')\n",
        "            axes[i].plot(test_dates_period, y_pred_denormalized, label='Predicted')\n",
        "            axes[i].set_title(f'{currency_orig}')\n",
        "            axes[i].set_xlabel('Date')\n",
        "            axes[i].set_ylabel('Exchange Rate')\n",
        "            axes[i].legend()\n",
        "            axes[i].tick_params(axis='x', rotation=45) # Rotate x-axis labels\n",
        "\n",
        "        plt.tight_layout() # Adjust layout to prevent labels overlapping\n",
        "        plt.savefig(f'{period_name}_all_currencies_actual_vs_predicted.pdf') # Save the plot as PDF\n",
        "        plt.close() # Close the plot to free memory\n",
        "    else:\n",
        "        print(f\"No test data available for {period_name} plotting.\")\n",
        "\n",
        "\n",
        "# Combined RMSE and MAE Bar Plots by Period (as requested)\n",
        "periods_order = ['Full', 'Pre-subsidy', 'Post-subsidy']\n",
        "metrics_to_plot = ['RMSE', 'MAE']\n",
        "currency_colors = {'USD_NGN': 'blue', 'EUR_NGN': 'green', 'GBP_NGN': 'red'}\n",
        "\n",
        "for period_name in periods_order:\n",
        "    print(f\"\\nGenerating combined RMSE and MAE bar plots for {period_name} Period...\")\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    x = np.arange(len(original_currency_cols))\n",
        "    width = 0.35\n",
        "\n",
        "    # Get RMSE and MAE values for the current period across all currencies\n",
        "    rmse_values = [performance_metrics[currency_orig]['RMSE'].get(period_name, 0) for currency_orig in original_currency_cols]\n",
        "    mae_values = [performance_metrics[currency_orig]['MAE'].get(period_name, 0) for currency_orig in original_currency_cols]\n",
        "\n",
        "    # Create grouped bar plot for RMSE and MAE\n",
        "    bars1 = plt.bar(x - width/2, rmse_values, width, label='RMSE', color=[currency_colors[c] for c in original_currency_cols])\n",
        "    bars2 = plt.bar(x + width/2, mae_values, width, label='MAE', color=[currency_colors[c] for c in original_currency_cols])\n",
        "\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.title(f'{period_name} Period: RMSE and MAE across Currencies')\n",
        "    plt.xticks(x, original_currency_cols)\n",
        "    plt.legend()\n",
        "\n",
        "    # Add value labels on top of bars\n",
        "    def autolabel(bars):\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            plt.annotate(f'{height:.2f}',\n",
        "                         xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                         xytext=(0, 3),  # 3 points vertical offset\n",
        "                         textcoords=\"offset points\",\n",
        "                         ha='center', va='bottom')\n",
        "\n",
        "    autolabel(bars1)\n",
        "    autolabel(bars2)\n",
        "\n",
        "    plt.tight_layout() # Adjust layout to prevent labels overlapping\n",
        "    plt.savefig(f'{period_name}_rmse_mae_combined_bar_plot.pdf') # Save the plot as PDF\n",
        "    plt.close() # Close the plot to free memory\n",
        "\n",
        "print(\"\\n--- Plot Generation and Saving Complete ---\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "--- Calculating Performance Metrics ---\n",
            "\n",
            "Processing Full Period for Metrics...\n",
            "Training model for Full to calculate metrics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Performance Metrics for Full Test Set:\n",
            "    USD_NGN: RMSE=33.4333, MAE=29.0345\n",
            "    EUR_NGN: RMSE=200.6248, MAE=196.3051\n",
            "    GBP_NGN: RMSE=125.5230, MAE=121.5888\n",
            "\n",
            "Processing Pre-subsidy Period for Metrics...\n",
            "Training model for Pre-subsidy to calculate metrics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Performance Metrics for Pre-subsidy Test Set:\n",
            "    USD_NGN: RMSE=16.9509, MAE=16.4012\n",
            "    EUR_NGN: RMSE=22.6990, MAE=21.9108\n",
            "    GBP_NGN: RMSE=7.7473, MAE=6.3276\n",
            "\n",
            "Processing Post-subsidy Period for Metrics...\n",
            "Training model for Post-subsidy to calculate metrics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "WARNING:tensorflow:5 out of the last 16 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f4d4cd95120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f4d4cd95120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Performance Metrics for Post-subsidy Test Set:\n",
            "    USD_NGN: RMSE=35.6594, MAE=28.5162\n",
            "    EUR_NGN: RMSE=36.8112, MAE=28.1149\n",
            "    GBP_NGN: RMSE=40.7283, MAE=32.7213\n",
            "\n",
            "--- Performance Metrics Calculation Complete ---\n",
            "\n",
            "--- Generating and Saving Plots as PDFs ---\n",
            "\n",
            "Generating plots for Full Period...\n",
            "\n",
            "Generating plots for Pre-subsidy Period...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating plots for Post-subsidy Period...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating combined RMSE and MAE bar plots for Full Period...\n",
            "\n",
            "Generating combined RMSE and MAE bar plots for Pre-subsidy Period...\n",
            "\n",
            "Generating combined RMSE and MAE bar plots for Post-subsidy Period...\n",
            "\n",
            "--- Plot Generation and Saving Complete ---\n"
          ]
        }
      ]
    }
  ]
}