{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM8mVo9kQUhhterd+xR/sw0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaFuego20/exchange-rate-forecasting/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Single-cell end-to-end LSTM pipeline (Colab / Jupyter)\n",
        "# Load -> Prepare sequences -> Train 3 LSTMs (Full / Pre / Post) -> Evaluate (normalized + denorm) -> Plot & save results\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# -------------------------\n",
        "# 0. Reproducibility\n",
        "# -------------------------\n",
        "os.environ['PYTHONHASHSEED'] = '2'\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "random.seed(2)\n",
        "np.random.seed(2)\n",
        "tf.random.set_seed(2)\n",
        "\n",
        "# -------------------------\n",
        "# 1. PARAMETERS (edit if needed)\n",
        "# -------------------------\n",
        "N_TIMESTEPS = 10                # lookback window used in your snippets\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "PATIENCE = 10\n",
        "SUBSIDY_REMOVAL_DATE = pd.to_datetime('2023-05-29', format='%Y-%m-%d')\n",
        "\n",
        "# Paths - change if your files are elsewhere\n",
        "NORMALIZED_CSV = \"/content/normalized_data.csv\"       # contains USD_NGN_Norm, EUR_NGN_Norm, GBP_NGN_Norm and Date\n",
        "ORIGINAL_CSV = \"/content/merged_exchange_rates.csv\"   # contains USD_NGN, EUR_NGN, GBP_NGN and Date\n",
        "\n",
        "# Target column names (original and normalized)\n",
        "original_cols = ['USD_NGN', 'EUR_NGN', 'GBP_NGN']\n",
        "normalized_cols = ['USD_NGN_Norm', 'EUR_NGN_Norm', 'GBP_NGN_Norm']\n",
        "currencies = ['USD', 'EUR', 'GBP']\n",
        "\n",
        "# -------------------------\n",
        "# 2. Load normalized dataset (for training)\n",
        "# -------------------------\n",
        "df_norm = None\n",
        "try:\n",
        "    df_norm = pd.read_csv(NORMALIZED_CSV, parse_dates=['Date'])\n",
        "    df_norm.set_index('Date', inplace=True)\n",
        "    print(f\"Loaded normalized data: {NORMALIZED_CSV} (rows: {len(df_norm)})\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {NORMALIZED_CSV} not found. Please upload or adjust the path.\")\n",
        "except Exception as e:\n",
        "    print(\"Error loading normalized data:\", e)\n",
        "\n",
        "# Validate normalized columns\n",
        "if df_norm is None:\n",
        "    raise SystemExit(\"Normalized dataframe not loaded. Fix file path and re-run.\")\n",
        "missing_norm = [c for c in normalized_cols if c not in df_norm.columns]\n",
        "if missing_norm:\n",
        "    raise SystemExit(f\"Missing normalized columns: {missing_norm}. Ensure your CSV has these columns.\")\n",
        "\n",
        "# Keep only normalized columns used for modeling\n",
        "df_normalized = df_norm[normalized_cols].copy()\n",
        "\n",
        "# Ensure datetime index\n",
        "if not isinstance(df_normalized.index, pd.DatetimeIndex):\n",
        "    df_normalized.index = pd.to_datetime(df_normalized.index, errors='coerce')\n",
        "    df_normalized.dropna(axis=0, inplace=True)\n",
        "\n",
        "# -------------------------\n",
        "# 3. Helper: create sequences\n",
        "# -------------------------\n",
        "def create_sequences(data: np.ndarray, n_steps: int):\n",
        "    X, y = [], []\n",
        "    if len(data) <= n_steps:\n",
        "        return np.array(X), np.array(y)\n",
        "    for i in range(len(data) - n_steps):\n",
        "        X.append(data[i:i + n_steps])\n",
        "        y.append(data[i + n_steps])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# -------------------------\n",
        "# 4. Split into periods\n",
        "# -------------------------\n",
        "df_full = df_normalized.dropna().copy()\n",
        "df_pre = df_normalized[df_normalized.index < SUBSIDY_REMOVAL_DATE].dropna().copy()\n",
        "df_post = df_normalized[df_normalized.index >= SUBSIDY_REMOVAL_DATE].dropna().copy()\n",
        "\n",
        "print(f\"Full rows: {len(df_full)}, Pre rows: {len(df_pre)}, Post rows: {len(df_post)}\")\n",
        "\n",
        "# -------------------------\n",
        "# 5. Create sequences and train/test splits\n",
        "# -------------------------\n",
        "# Full\n",
        "X_full, y_full = create_sequences(df_full.values, N_TIMESTEPS)\n",
        "if X_full.size:\n",
        "    X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "        X_full, y_full, test_size=0.2, shuffle=False, random_state=2)\n",
        "else:\n",
        "    X_train_full = X_test_full = y_train_full = y_test_full = np.array([])\n",
        "\n",
        "# Pre\n",
        "X_pre, y_pre = create_sequences(df_pre.values, N_TIMESTEPS)\n",
        "if X_pre.size:\n",
        "    X_train_pre, X_test_pre, y_train_pre, y_test_pre = train_test_split(\n",
        "        X_pre, y_pre, test_size=0.2, shuffle=False, random_state=2)\n",
        "else:\n",
        "    X_train_pre = X_test_pre = y_train_pre = y_test_pre = np.array([])\n",
        "\n",
        "# Post\n",
        "X_post, y_post = create_sequences(df_post.values, N_TIMESTEPS)\n",
        "if X_post.size:\n",
        "    X_train_post, X_test_post, y_train_post, y_test_post = train_test_split(\n",
        "        X_post, y_post, test_size=0.2, shuffle=False, random_state=2)\n",
        "else:\n",
        "    X_train_post = X_test_post = y_train_post = y_test_post = np.array([])\n",
        "\n",
        "# Print shapes for verification\n",
        "def print_shapes(label, Xtr, Xte, ytr, yte):\n",
        "    if isinstance(Xtr, np.ndarray) and Xtr.size:\n",
        "        print(f\"{label} -> X_train: {Xtr.shape}, X_test: {Xte.shape}, y_train: {ytr.shape}, y_test: {yte.shape}\")\n",
        "    else:\n",
        "        print(f\"{label} -> Not enough data for sequences (skipped).\")\n",
        "\n",
        "print_shapes('Full', X_train_full, X_test_full, y_train_full, y_test_full)\n",
        "print_shapes('Pre', X_train_pre, X_test_pre, y_train_pre, y_test_pre)\n",
        "print_shapes('Post', X_train_post, X_test_post, y_train_post, y_test_post)\n",
        "\n",
        "# -------------------------\n",
        "# 6. Model builder helper\n",
        "# -------------------------\n",
        "def build_lstm_model(n_timesteps, n_features, n_outputs):\n",
        "    model = Sequential([\n",
        "        LSTM(64, activation='relu', input_shape=(n_timesteps, n_features)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(n_outputs)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)\n",
        "\n",
        "# -------------------------\n",
        "# 7. Train models (Full, Pre, Post)\n",
        "# -------------------------\n",
        "model_full = None\n",
        "if isinstance(X_train_full, np.ndarray) and X_train_full.size:\n",
        "    model_full = build_lstm_model(N_TIMESTEPS, X_train_full.shape[2], y_train_full.shape[1])\n",
        "    print(\"Full model summary:\")\n",
        "    model_full.summary()\n",
        "    if isinstance(X_test_full, np.ndarray) and X_test_full.size:\n",
        "        model_full.fit(X_train_full, y_train_full, validation_data=(X_test_full, y_test_full),\n",
        "                       epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[early_stop], verbose=0)\n",
        "    else:\n",
        "        model_full.fit(X_train_full, y_train_full, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "                       callbacks=[early_stop], verbose=0)\n",
        "    print(\"Trained Full model.\")\n",
        "\n",
        "model_pre = None\n",
        "if isinstance(X_train_pre, np.ndarray) and X_train_pre.size:\n",
        "    model_pre = build_lstm_model(N_TIMESTEPS, X_train_pre.shape[2], y_train_pre.shape[1])\n",
        "    print(\"Pre model summary:\")\n",
        "    model_pre.summary()\n",
        "    if isinstance(X_test_pre, np.ndarray) and X_test_pre.size:\n",
        "        model_pre.fit(X_train_pre, y_train_pre, validation_data=(X_test_pre, y_test_pre),\n",
        "                      epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[early_stop], verbose=0)\n",
        "    else:\n",
        "        model_pre.fit(X_train_pre, y_train_pre, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "                      callbacks=[early_stop], verbose=0)\n",
        "    print(\"Trained Pre-subsidy model.\")\n",
        "\n",
        "model_post = None\n",
        "if isinstance(X_train_post, np.ndarray) and X_train_post.size:\n",
        "    model_post = build_lstm_model(N_TIMESTEPS, X_train_post.shape[2], y_train_post.shape[1])\n",
        "    print(\"Post model summary:\")\n",
        "    model_post.summary()\n",
        "    if isinstance(X_test_post, np.ndarray) and X_test_post.size:\n",
        "        model_post.fit(X_train_post, y_train_post, validation_data=(X_test_post, y_test_post),\n",
        "                       epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[early_stop], verbose=0)\n",
        "    else:\n",
        "        model_post.fit(X_train_post, y_train_post, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "                       callbacks=[early_stop], verbose=0)\n",
        "    print(\"Trained Post-subsidy model.\")\n",
        "\n",
        "# -------------------------\n",
        "# 8. Predictions & Normalized Metrics\n",
        "# -------------------------\n",
        "metrics_summary = {}\n",
        "\n",
        "# Full\n",
        "y_pred_full = np.array([])\n",
        "if model_full is not None and isinstance(X_test_full, np.ndarray) and X_test_full.size:\n",
        "    y_pred_full = model_full.predict(X_test_full, verbose=0)\n",
        "    rmse_full = np.sqrt(mean_squared_error(y_test_full, y_pred_full))\n",
        "    mae_full = mean_absolute_error(y_test_full, y_pred_full)\n",
        "    rmse_full_currency = [np.sqrt(mean_squared_error(y_test_full[:, i], y_pred_full[:, i])) for i in range(len(currencies))]\n",
        "    mae_full_currency = [mean_absolute_error(y_test_full[:, i], y_pred_full[:, i]) for i in range(len(currencies))]\n",
        "    metrics_summary['Full'] = {'RMSE_Overall': rmse_full, 'MAE_Overall': mae_full,\n",
        "                               'RMSE_Currency': rmse_full_currency, 'MAE_Currency': mae_full_currency}\n",
        "else:\n",
        "    metrics_summary['Full'] = {'RMSE_Overall': None, 'MAE_Overall': None, 'RMSE_Currency': [], 'MAE_Currency': []}\n",
        "\n",
        "# Pre\n",
        "y_pred_pre = np.array([])\n",
        "if model_pre is not None and isinstance(X_test_pre, np.ndarray) and X_test_pre.size:\n",
        "    y_pred_pre = model_pre.predict(X_test_pre, verbose=0)\n",
        "    rmse_pre = np.sqrt(mean_squared_error(y_test_pre, y_pred_pre))\n",
        "    mae_pre = mean_absolute_error(y_test_pre, y_pred_pre)\n",
        "    rmse_pre_currency = [np.sqrt(mean_squared_error(y_test_pre[:, i], y_pred_pre[:, i])) for i in range(len(currencies))]\n",
        "    mae_pre_currency = [mean_absolute_error(y_test_pre[:, i], y_pred_pre[:, i]) for i in range(len(currencies))]\n",
        "    metrics_summary['Pre-Subsidy'] = {'RMSE_Overall': rmse_pre, 'MAE_Overall': mae_pre,\n",
        "                                      'RMSE_Currency': rmse_pre_currency, 'MAE_Currency': mae_pre_currency}\n",
        "else:\n",
        "    metrics_summary['Pre-Subsidy'] = {'RMSE_Overall': None, 'MAE_Overall': None, 'RMSE_Currency': [], 'MAE_Currency': []}\n",
        "\n",
        "# Post\n",
        "y_pred_post = np.array([])\n",
        "if model_post is not None and isinstance(X_test_post, np.ndarray) and X_test_post.size:\n",
        "    y_pred_post = model_post.predict(X_test_post, verbose=0)\n",
        "    rmse_post = np.sqrt(mean_squared_error(y_test_post, y_pred_post))\n",
        "    mae_post = mean_absolute_error(y_test_post, y_pred_post)\n",
        "    rmse_post_currency = [np.sqrt(mean_squared_error(y_test_post[:, i], y_pred_post[:, i])) for i in range(len(currencies))]\n",
        "    mae_post_currency = [mean_absolute_error(y_test_post[:, i], y_pred_post[:, i]) for i in range(len(currencies))]\n",
        "    metrics_summary['Post-Subsidy'] = {'RMSE_Overall': rmse_post, 'MAE_Overall': mae_post,\n",
        "                                       'RMSE_Currency': rmse_post_currency, 'MAE_Currency': mae_post_currency}\n",
        "else:\n",
        "    metrics_summary['Post-Subsidy'] = {'RMSE_Overall': None, 'MAE_Overall': None, 'RMSE_Currency': [], 'MAE_Currency': []}\n",
        "\n",
        "print(\"\\n--- Normalized metrics (from normalized data) ---\")\n",
        "display(metrics_summary)\n",
        "\n",
        "# Save normalized metrics to CSV-friendly dataframe (optional)\n",
        "try:\n",
        "    norm_df_rows = []\n",
        "    for period, d in metrics_summary.items():\n",
        "        row = {\n",
        "            'Period': period,\n",
        "            'RMSE_Overall': d['RMSE_Overall'],\n",
        "            'MAE_Overall': d['MAE_Overall']\n",
        "        }\n",
        "        for i, c in enumerate(currencies):\n",
        "            row[f'RMSE_{c}'] = d['RMSE_Currency'][i] if d['RMSE_Currency'] else None\n",
        "            row[f'MAE_{c}'] = d['MAE_Currency'][i] if d['MAE_Currency'] else None\n",
        "        norm_df_rows.append(row)\n",
        "    norm_metrics_df = pd.DataFrame(norm_df_rows)\n",
        "    norm_metrics_df.to_csv('lstm_normalized_metrics_summary.csv', index=False)\n",
        "    print(\"Saved lstm_normalized_metrics_summary.csv\")\n",
        "except Exception as e:\n",
        "    print(\"Could not save normalized metrics CSV:\", e)\n",
        "\n",
        "# -------------------------\n",
        "# 9. Denormalize predictions & test sets (min-max)\n",
        "# -------------------------\n",
        "df_orig = None\n",
        "try:\n",
        "    df_orig = pd.read_csv(ORIGINAL_CSV, parse_dates=['Date'], dayfirst=True)\n",
        "    df_orig.set_index('Date', inplace=True)\n",
        "    print(f\"Loaded original data: {ORIGINAL_CSV} (rows: {len(df_orig)})\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Warning: {ORIGINAL_CSV} not found. Denormalization skipped.\")\n",
        "except Exception as e:\n",
        "    print(\"Warning: error loading original CSV, denormalization may fail:\", e)\n",
        "\n",
        "min_vals = None\n",
        "max_vals = None\n",
        "if df_orig is not None:\n",
        "    missing_orig = [c for c in original_cols if c not in df_orig.columns]\n",
        "    if missing_orig:\n",
        "        print(\"Warning: original file missing columns:\", missing_orig)\n",
        "    else:\n",
        "        min_vals = df_orig[original_cols].min()\n",
        "        max_vals = df_orig[original_cols].max()\n",
        "\n",
        "# Denormalize helper (expects arrays shape (samples, 3))\n",
        "def denormalize_array(arr_norm, min_vals, max_vals):\n",
        "    if arr_norm is None or arr_norm.size == 0:\n",
        "        return np.array([])\n",
        "    scale = (max_vals.values - min_vals.values)\n",
        "    return arr_norm * scale + min_vals.values\n",
        "\n",
        "y_test_full_denorm = denormalize_array(y_test_full, min_vals, max_vals) if min_vals is not None else np.array([])\n",
        "y_pred_full_denorm = denormalize_array(y_pred_full, min_vals, max_vals) if min_vals is not None else np.array([])\n",
        "\n",
        "y_test_pre_denorm = denormalize_array(y_test_pre, min_vals, max_vals) if min_vals is not None else np.array([])\n",
        "y_pred_pre_denorm = denormalize_array(y_pred_pre, min_vals, max_vals) if min_vals is not None else np.array([])\n",
        "\n",
        "y_test_post_denorm = denormalize_array(y_test_post, min_vals, max_vals) if min_vals is not None else np.array([])\n",
        "y_pred_post_denorm = denormalize_array(y_pred_post, min_vals, max_vals) if min_vals is not None else np.array([])\n",
        "\n",
        "# Recalculate denormalized metrics\n",
        "rmse_full_currency_denorm = []\n",
        "mae_full_currency_denorm = []\n",
        "rmse_pre_list_denorm = []\n",
        "mae_pre_list_denorm = []\n",
        "rmse_post_list_denorm = []\n",
        "mae_post_list_denorm = []\n",
        "\n",
        "print(\"\\n--- Denormalized metrics (if original CSV was provided) ---\")\n",
        "if y_test_full_denorm.size:\n",
        "    for i, name in enumerate(currencies):\n",
        "        rmse = np.sqrt(mean_squared_error(y_test_full_denorm[:, i], y_pred_full_denorm[:, i]))\n",
        "        mae = mean_absolute_error(y_test_full_denorm[:, i], y_pred_full_denorm[:, i])\n",
        "        rmse_full_currency_denorm.append(rmse)\n",
        "        mae_full_currency_denorm.append(mae)\n",
        "        print(f\"Full {name} - RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "\n",
        "if y_test_pre_denorm.size:\n",
        "    for i, name in enumerate(currencies):\n",
        "        rmse = np.sqrt(mean_squared_error(y_test_pre_denorm[:, i], y_pred_pre_denorm[:, i]))\n",
        "        mae = mean_absolute_error(y_test_pre_denorm[:, i], y_pred_pre_denorm[:, i])\n",
        "        rmse_pre_list_denorm.append(rmse)\n",
        "        mae_pre_list_denorm.append(mae)\n",
        "        print(f\"Pre {name} - RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "\n",
        "if y_test_post_denorm.size:\n",
        "    for i, name in enumerate(currencies):\n",
        "        rmse = np.sqrt(mean_squared_error(y_test_post_denorm[:, i], y_pred_post_denorm[:, i]))\n",
        "        mae = mean_absolute_error(y_test_post_denorm[:, i], y_pred_post_denorm[:, i])\n",
        "        rmse_post_list_denorm.append(rmse)\n",
        "        mae_post_list_denorm.append(mae)\n",
        "        print(f\"Post {name} - RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "\n",
        "# Save denormalized metrics (if computed)\n",
        "try:\n",
        "    denorm_df_rows = []\n",
        "    if rmse_full_currency_denorm:\n",
        "        denorm_df_rows.append({'Period':'Full', **{f'RMSE_{c}': rmse_full_currency_denorm[i] for i,c in enumerate(currencies)}, **{f'MAE_{c}': mae_full_currency_denorm[i] for i,c in enumerate(currencies)}})\n",
        "    if rmse_pre_list_denorm:\n",
        "        denorm_df_rows.append({'Period':'Pre-Subsidy', **{f'RMSE_{c}': rmse_pre_list_denorm[i] for i,c in enumerate(currencies)}, **{f'MAE_{c}': mae_pre_list_denorm[i] for i,c in enumerate(currencies)}})\n",
        "    if rmse_post_list_denorm:\n",
        "        denorm_df_rows.append({'Period':'Post-Subsidy', **{f'RMSE_{c}': rmse_post_list_denorm[i] for i,c in enumerate(currencies)}, **{f'MAE_{c}': mae_post_list_denorm[i] for i,c in enumerate(currencies)}})\n",
        "    if denorm_df_rows:\n",
        "        denorm_metrics_df = pd.DataFrame(denorm_df_rows)\n",
        "        denorm_metrics_df.to_csv('lstm_denormalized_metrics_summary.csv', index=False)\n",
        "        print(\"Saved lstm_denormalized_metrics_summary.csv\")\n",
        "except Exception as e:\n",
        "    print(\"Could not save denormalized metrics CSV:\", e)\n",
        "\n",
        "# -------------------------\n",
        "# 10. Plotting - align dates and plot Actual vs Predicted (denorm if available, else normalized)\n",
        "# -------------------------\n",
        "def get_sequence_dates(dataframe, n_steps):\n",
        "    if not isinstance(dataframe.index, pd.DatetimeIndex):\n",
        "        dataframe.index = pd.to_datetime(dataframe.index, errors='coerce')\n",
        "        dataframe.dropna(axis=0, inplace=True)\n",
        "    if len(dataframe) <= n_steps:\n",
        "        return pd.Index([])\n",
        "    return dataframe.index[n_steps:]\n",
        "\n",
        "dates_full_seq = get_sequence_dates(df_full, N_TIMESTEPS)\n",
        "dates_pre_seq = get_sequence_dates(df_pre, N_TIMESTEPS)\n",
        "dates_post_seq = get_sequence_dates(df_post, N_TIMESTEPS)\n",
        "\n",
        "dates_test_full = dates_full_seq[-len(y_test_full):] if isinstance(y_test_full, np.ndarray) and y_test_full.size and len(dates_full_seq) >= len(y_test_full) else pd.Index([])\n",
        "dates_test_pre = dates_pre_seq[-len(y_test_pre):] if isinstance(y_test_pre, np.ndarray) and y_test_pre.size and len(dates_pre_seq) >= len(y_test_pre) else pd.Index([])\n",
        "dates_test_post = dates_post_seq[-len(y_test_post):] if isinstance(y_test_post, np.ndarray) and y_test_post.size and len(dates_post_seq) >= len(y_test_post) else pd.Index([])\n",
        "\n",
        "# plotting preferences: Actual = blue, Predicted = orange\n",
        "actual_color = 'blue'\n",
        "pred_color = 'orange'\n",
        "\n",
        "# Helper to build DataFrame for plotting (choose denorm if available)\n",
        "def build_plot_df(dates, y_test_arr, y_pred_arr, denorm_test, denorm_pred):\n",
        "    if dates.empty or y_test_arr is None or y_pred_arr is None or y_test_arr.size == 0:\n",
        "        return None\n",
        "    if denorm_test is not None and denorm_test.size:\n",
        "        df_act = pd.DataFrame(denorm_test, index=dates, columns=currencies)\n",
        "        df_pred = pd.DataFrame(denorm_pred, index=dates, columns=currencies)\n",
        "    else:\n",
        "        df_act = pd.DataFrame(y_test_arr, index=dates, columns=currencies)\n",
        "        df_pred = pd.DataFrame(y_pred_arr, index=dates, columns=currencies)\n",
        "    return df_act, df_pred\n",
        "\n",
        "# Pre plot\n",
        "if not dates_test_pre.empty:\n",
        "    plot_pair = build_plot_df(dates_test_pre, y_test_pre, y_pred_pre, y_test_pre_denorm, y_pred_pre_denorm)\n",
        "    if plot_pair is not None:\n",
        "        df_act_pre, df_pred_pre = plot_pair\n",
        "        plt.figure(figsize=(12, 12))\n",
        "        for i, col in enumerate(currencies):\n",
        "            plt.subplot(3, 1, i+1)\n",
        "            plt.plot(df_act_pre.index, df_act_pre[col], label='Actual (Pre)', color=actual_color)\n",
        "            plt.plot(df_pred_pre.index, df_pred_pre[col], label='Predicted (Pre)', color=pred_color)\n",
        "            plt.title(f'LSTM Forecast — Pre-Subsidy ({col}/NGN)')\n",
        "            plt.xlabel('Date')\n",
        "            plt.ylabel('Exchange Rate' + (' (₦)' if y_test_pre_denorm.size else ' (Normalized)'))\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('lstm_pre_subsidy_actual_vs_predicted.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "# Post plot\n",
        "if not dates_test_post.empty:\n",
        "    plot_pair = build_plot_df(dates_test_post, y_test_post, y_pred_post, y_test_post_denorm, y_pred_post_denorm)\n",
        "    if plot_pair is not None:\n",
        "        df_act_post, df_pred_post = plot_pair\n",
        "        plt.figure(figsize=(12, 12))\n",
        "        for i, col in enumerate(currencies):\n",
        "            plt.subplot(3, 1, i+1)\n",
        "            plt.plot(df_act_post.index, df_act_post[col], label='Actual (Post)', color=actual_color)\n",
        "            plt.plot(df_pred_post.index, df_pred_post[col], label='Predicted (Post)', color=pred_color)\n",
        "            plt.title(f'LSTM Forecast — Post-Subsidy ({col}/NGN)')\n",
        "            plt.xlabel('Date')\n",
        "            plt.ylabel('Exchange Rate' + (' (₦)' if y_test_post_denorm.size else ' (Normalized)'))\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('lstm_post_subsidy_actual_vs_predicted.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "# Combined pre+post (actuals) with combined predicted series\n",
        "if (not dates_test_pre.empty) and (not dates_test_post.empty):\n",
        "    # Build frames (use denorm if available)\n",
        "    pre_pair = build_plot_df(dates_test_pre, y_test_pre, y_pred_pre, y_test_pre_denorm, y_pred_pre_denorm)\n",
        "    post_pair = build_plot_df(dates_test_post, y_test_post, y_pred_post, y_test_post_denorm, y_pred_post_denorm)\n",
        "    if pre_pair is not None and post_pair is not None:\n",
        "        df_pre_act, df_pre_pred = pre_pair\n",
        "        df_post_act, df_post_pred = post_pair\n",
        "        plt.figure(figsize=(12, 12))\n",
        "        for i, col in enumerate(currencies):\n",
        "            plt.subplot(3, 1, i+1)\n",
        "            plt.plot(df_pre_act.index, df_pre_act[col], label='Actual (Pre)', color='blue')\n",
        "            plt.plot(df_post_act.index, df_post_act[col], label='Actual (Post)', color='darkblue')\n",
        "            combined_pred = pd.concat([df_pre_pred[col], df_post_pred[col]]).sort_index()\n",
        "            plt.plot(combined_pred.index, combined_pred.values, label='Predicted (Combined)', color='orange', linestyle='--')\n",
        "            plt.axvline(SUBSIDY_REMOVAL_DATE, color='gray', linestyle=':', label='Subsidy Removal Date')\n",
        "            plt.title(f'Actual vs Predicted — Pre & Post ({col}/NGN)')\n",
        "            plt.xlabel('Date')\n",
        "            plt.ylabel('Exchange Rate' + (' (₦)' if (y_test_pre_denorm.size or y_test_post_denorm.size) else ' (Normalized)'))\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.xticks(rotation=30)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('lstm_combined_pre_post_actual_vs_predicted.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "# -------------------------\n",
        "# 11. Bar charts for normalized and denormalized RMSE/MAE\n",
        "# -------------------------\n",
        "# Normalized metrics (from earlier metrics_summary)\n",
        "try:\n",
        "    rmse_pre_list = metrics_summary['Pre-Subsidy']['RMSE_Currency']\n",
        "    mae_pre_list = metrics_summary['Pre-Subsidy']['MAE_Currency']\n",
        "    rmse_post_list = metrics_summary['Post-Subsidy']['RMSE_Currency']\n",
        "    mae_post_list = metrics_summary['Post-Subsidy']['MAE_Currency']\n",
        "    if rmse_pre_list and rmse_post_list and mae_pre_list and mae_post_list:\n",
        "        x = np.arange(len(currencies))\n",
        "        width = 0.35\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14,6))\n",
        "        # RMSE normalized\n",
        "        axes[0].bar(x - width/2, rmse_pre_list, width, label='Pre-Subsidy')\n",
        "        axes[0].bar(x + width/2, rmse_post_list, width, label='Post-Subsidy')\n",
        "        axes[0].set_xticks(x); axes[0].set_xticklabels(currencies)\n",
        "        axes[0].set_title('Normalized RMSE: Pre vs Post')\n",
        "        axes[0].legend(); axes[0].grid(axis='y', linestyle='--', alpha=0.6)\n",
        "        # annotate\n",
        "        for rect in axes[0].patches: pass\n",
        "        # MAE normalized\n",
        "        axes[1].bar(x - width/2, mae_pre_list, width, label='Pre-Subsidy')\n",
        "        axes[1].bar(x + width/2, mae_post_list, width, label='Post-Subsidy')\n",
        "        axes[1].set_xticks(x); axes[1].set_xticklabels(currencies)\n",
        "        axes[1].set_title('Normalized MAE: Pre vs Post')\n",
        "        axes[1].legend(); axes[1].grid(axis='y', linestyle='--', alpha=0.6)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('lstm_normalized_rmse_mae_bar.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Skipping normalized RMSE/MAE bar chart (insufficient normalized metrics).\")\n",
        "except Exception as e:\n",
        "    print(\"Skipping normalized RMSE/MAE bar chart due to error:\", e)\n",
        "\n",
        "# Denormalized metrics (if computed)\n",
        "try:\n",
        "    if rmse_pre_list_denorm and rmse_post_list_denorm and mae_pre_list_denorm and mae_post_list_denorm:\n",
        "        x = np.arange(len(currencies))\n",
        "        width = 0.35\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14,6))\n",
        "        axes[0].bar(x - width/2, rmse_pre_list_denorm, width, label='Pre-Subsidy')\n",
        "        axes[0].bar(x + width/2, rmse_post_list_denorm, width, label='Post-Subsidy')\n",
        "        axes[0].set_xticks(x); axes[0].set_xticklabels(currencies)\n",
        "        axes[0].set_title('Denormalized RMSE: Pre vs Post')\n",
        "        axes[0].legend(); axes[0].grid(axis='y', linestyle='--', alpha=0.6)\n",
        "        axes[1].bar(x - width/2, mae_pre_list_denorm, width, label='Pre-Subsidy')\n",
        "        axes[1].bar(x + width/2, mae_post_list_denorm, width, label='Post-Subsidy')\n",
        "        axes[1].set_xticks(x); axes[1].set_xticklabels(currencies)\n",
        "        axes[1].set_title('Denormalized MAE: Pre vs Post')\n",
        "        axes[1].legend(); axes[1].grid(axis='y', linestyle='--', alpha=0.6)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('lstm_denormalized_rmse_mae_bar.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Skipping denormalized RMSE/MAE bar chart (insufficient denormalized metrics).\")\n",
        "except Exception as e:\n",
        "    print(\"Skipping denormalized RMSE/MAE bar chart due to error:\", e)\n",
        "\n",
        "# -------------------------\n",
        "# 12. Final: print & save summary\n",
        "# -------------------------\n",
        "print(\"\\nFinal metrics summary (normalized):\")\n",
        "display(norm_metrics_df)\n",
        "\n",
        "if 'denorm_metrics_df' in locals():\n",
        "    print(\"\\nFinal metrics summary (denormalized):\")\n",
        "    display(denorm_metrics_df)\n",
        "\n",
        "print(\"\\nAll done. Figures saved to current working directory.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1BZRQAHoeosy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}